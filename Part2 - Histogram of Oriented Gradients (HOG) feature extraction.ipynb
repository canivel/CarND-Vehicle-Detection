{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.feature import hog\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loaded\n"
     ]
    }
   ],
   "source": [
    "cars_ds_file = 'cars_data.p'\n",
    "with open(cars_ds_file, mode='rb') as f:\n",
    "    ds = pickle.load(f)\n",
    "cars_train = ds['cars_train']\n",
    "notcars_train = ds['notcars_train']\n",
    "cars_val = ds['cars_val']\n",
    "notcars_val = ds['notcars_val']\n",
    "cars_test = ds['cars_test']\n",
    "notcars_test = ds['notcars_test']\n",
    "\n",
    "print(\"dataset loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Histogram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting extract Car Features\n",
      "Starting extract Not Car Features\n",
      "Features Extracted in: 91.2s\n"
     ]
    }
   ],
   "source": [
    "color_space = 'HLS' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "spatial_size = (16, 16)\n",
    "hist_bins = 32\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "hog_channel = 'ALL'\n",
    "spatial_features = True\n",
    "hist_features = True\n",
    "hog_features = True\n",
    "\n",
    "t=time.time()\n",
    "print('Starting extract Car Features')\n",
    "cars_train_features = utils.extract_features_bulk(cars_train,color_space, spatial_size,hist_bins, orient, \n",
    "                               pix_per_cell, cell_per_block, hog_channel, spatial_features, hist_features, hog_features)\n",
    "cars_val_features = utils.extract_features_bulk(cars_val,color_space, spatial_size,hist_bins, orient, \n",
    "                               pix_per_cell, cell_per_block, hog_channel, spatial_features, hist_features, hog_features)\n",
    "cars_test_features = utils.extract_features_bulk(cars_test,color_space, spatial_size,hist_bins, orient, \n",
    "                               pix_per_cell, cell_per_block, hog_channel, spatial_features, hist_features, hog_features)\n",
    "\n",
    "print('Starting extract Not Car Features')\n",
    "notcars_train_features = utils.extract_features_bulk(notcars_train,color_space, spatial_size,hist_bins, orient, \n",
    "                               pix_per_cell, cell_per_block, hog_channel, spatial_features, hist_features, hog_features)\n",
    "notcars_val_features = utils.extract_features_bulk(notcars_val,color_space, spatial_size,hist_bins, orient, \n",
    "                               pix_per_cell, cell_per_block, hog_channel, spatial_features, hist_features, hog_features)\n",
    "notcars_test_features = utils.extract_features_bulk(notcars_test,color_space, spatial_size,hist_bins, orient, \n",
    "                               pix_per_cell, cell_per_block, hog_channel, spatial_features, hist_features, hog_features)\n",
    "t2 = time.time()\n",
    "print('Features Extracted in: {}s'.format(round(t2-t, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Normalize the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an array stack of feature vectors\n",
    "X = np.vstack((cars_train_features, cars_val_features, cars_test_features, \n",
    "               notcars_train_features, notcars_val_features, notcars_test_features)).astype(np.float64)\n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.20444453 -0.50679381 -0.53345294 ..., -0.11410046 -0.32320719\n",
      "   0.81947684]\n",
      " [-0.87703451  1.20109641 -0.62255031 ..., -0.70628552 -0.29875005\n",
      "   0.17515005]\n",
      " [-0.32630026 -0.96528784 -0.40832241 ..., -0.89872948 -0.81191714\n",
      "  -0.66705859]\n",
      " ..., \n",
      " [ 1.51984988 -0.97904265  0.17590576 ..., -0.93618384 -0.97603736\n",
      "  -0.84128332]\n",
      " [-0.29675449 -0.37612307 -0.46834722 ...,  0.22227731  1.68476253\n",
      "   0.09464588]\n",
      " [ 0.47215278  1.19421883 -0.2478553  ..., -0.62191524  0.68598843\n",
      "  -0.50925073]]\n"
     ]
    }
   ],
   "source": [
    "print(scaled_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6154 = 6154\n",
      "1758 = 1758\n",
      "880 = 880\n"
     ]
    }
   ],
   "source": [
    "# Split back the training, validation and test features for Cars\n",
    "n_cars_train_features = len(cars_train_features)\n",
    "n_cars_val_features = len(cars_val_features)\n",
    "n_cars_test_features = len(cars_test_features)\n",
    "\n",
    "cars_train_features = scaled_X[:n_cars_train_features]\n",
    "cars_val_features = scaled_X[n_cars_train_features:n_cars_train_features+n_cars_val_features]\n",
    "cars_test_features = scaled_X[n_cars_train_features+n_cars_val_features:n_cars_train_features+n_cars_val_features+n_cars_test_features]\n",
    "\n",
    "print('{} = {}'.format(n_cars_train_features, len(cars_train_features)))\n",
    "print('{} = {}'.format(n_cars_val_features, len(cars_val_features)))\n",
    "print('{} = {}'.format(n_cars_test_features, len(cars_test_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6277 = 6277\n",
      "1794 = 1794\n",
      "897 = 897\n"
     ]
    }
   ],
   "source": [
    "# Split back the training, validation and test features for NotCars\n",
    "n_notcars_train_features = len(notcars_train_features)\n",
    "n_notcars_val_features = len(notcars_val_features)\n",
    "n_notcars_test_features = len(notcars_test_features)\n",
    "\n",
    "notcars_train_features = scaled_X[:n_notcars_train_features]\n",
    "notcars_val_features = scaled_X[n_notcars_train_features:n_notcars_train_features+n_notcars_val_features]\n",
    "notcars_test_features = scaled_X[n_notcars_train_features+n_notcars_val_features:n_notcars_train_features+n_notcars_val_features+n_notcars_test_features]\n",
    "\n",
    "print('{} = {}'.format(n_notcars_train_features, len(notcars_train_features)))\n",
    "print('{} = {}'.format(n_notcars_val_features, len(notcars_val_features)))\n",
    "print('{} = {}'.format(n_notcars_test_features, len(notcars_test_features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the arrays for the features and labels to be trained, validate and tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12431 = 12431\n",
      "3552 = 3552\n",
      "1777 = 1777\n"
     ]
    }
   ],
   "source": [
    "# ## Create the labels vector, 1 if car, 0 if not car\n",
    "y_train = np.hstack((np.ones(n_cars_train_features), np.zeros(n_notcars_train_features)))\n",
    "y_val = np.hstack((np.ones(n_cars_val_features), np.zeros(n_notcars_val_features)))\n",
    "y_test = np.hstack((np.ones(n_cars_test_features), np.zeros(n_notcars_test_features)))\n",
    "\n",
    "# # Create an array stack of feature vectors\n",
    "\n",
    "_s1 = n_cars_train_features\n",
    "_s2 = _s1 + n_cars_val_features\n",
    "_s3 = _s2 + n_cars_test_features\n",
    "_s4 = _s3 + n_notcars_train_features\n",
    "_s5 = _s4 + n_notcars_val_features\n",
    "\n",
    "\n",
    "X_train = np.vstack((scaled_X[:_s1],scaled_X[_s3:_s4]))\n",
    "X_val = np.vstack((scaled_X[_s1:_s2],scaled_X[_s4:_s5]))\n",
    "X_test = np.vstack((scaled_X[_s2:_s3],scaled_X[_s5:]))\n",
    "\n",
    "X_train,y_train = shuffle(X_train,y_train,random_state=42)\n",
    "X_val,y_val = shuffle(X_val,y_val,random_state=42)\n",
    "X_test,y_test = shuffle(X_test,y_test,random_state=42)\n",
    "\n",
    "print('{} = {}'.format(len(X_train), len(y_train)))\n",
    "print('{} = {}'.format(len(X_val), len(y_val)))\n",
    "print('{} = {}'.format(len(X_test), len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model, tunning, test accuracy and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'C': 0.01} with a score of 0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "C_range = np.logspace(-2, 1, 10)\n",
    "param_grid = dict(C=C_range)\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(LinearSVC(), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X_val, y_val)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: 9 orientations 8 pixels per cell and 2 cells per block\n",
      "Feature vector length: 6156\n",
      "10.94 Seconds to train SVC...\n",
      "Validation Accuracy of SVC =  0.9901\n",
      "Test Accuracy of SVC =  0.9859\n",
      "0.0 Seconds to predict 500 labels with SVC\n"
     ]
    }
   ],
   "source": [
    "print('Using:',orient,'orientations',pix_per_cell,\n",
    "    'pixels per cell and', cell_per_block,'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "# Use a linear SVC\n",
    "svc = LinearSVC(C=0.01)\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Validation Accuracy of SVC = ', round(svc.score(X_val, y_val), 4))\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = 500\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the data for Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving pre processed...\n",
      "preprocessed_dataset.p saved.\n",
      "Saving classifier file...\n",
      "classifier_data.p saved.\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'preprocessed_dataset.p'\n",
    "print('Saving pre processed...')\n",
    "try:\n",
    "    with open(pickle_file, 'wb') as pfile:\n",
    "        pickle.dump(\n",
    "            {                    \n",
    "                'X_train': X_train,\n",
    "                'X_val': X_val,\n",
    "                'X_test': X_test,\n",
    "                'y_train': y_train,\n",
    "                'y_val': y_val,\n",
    "                'y_test': y_test,\n",
    "                \n",
    "            },\n",
    "            pfile, pickle.HIGHEST_PROTOCOL)\n",
    "except Exception as e:\n",
    "    print('Unable to save data to', pickle_file, ':', e)\n",
    "    raise\n",
    "    \n",
    "print('preprocessed_dataset.p saved.')\n",
    "\n",
    "\n",
    "pickle_file = 'classifier_data.p'\n",
    "print('Saving classifier file...')\n",
    "try:\n",
    "    with open(pickle_file, 'wb') as pfile:\n",
    "        pickle.dump(\n",
    "            {   'svc':svc, \n",
    "                'X_scaler': X_scaler,\n",
    "                'color_space': color_space,\n",
    "                'spatial_size': spatial_size,\n",
    "                'hist_bins': hist_bins,\n",
    "                'orient': orient,\n",
    "                'pix_per_cell': pix_per_cell,\n",
    "                'cell_per_block': cell_per_block,\n",
    "                'hog_channel': hog_channel,\n",
    "                'spatial_features': spatial_features,\n",
    "                'hist_features': hist_features,\n",
    "                'hog_features':hog_features\n",
    "            },\n",
    "            pfile, pickle.HIGHEST_PROTOCOL)\n",
    "except Exception as e:\n",
    "    print('Unable to save data to', pickle_file, ':', e)\n",
    "    raise\n",
    "\n",
    "print('classifier_data.p saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
